AI Security Summary â€“ AI Risk Atlas: Taxonomy and Tooling for Navigating AI Risks and Resources

1. Overview

AI Risk Atlas: Consolidates risks from multiple sources into a unified taxonomy.
Focus on Generative AI and Agentic AI, highlighting unique security and governance challenges.
Risk Atlas Nexus: Open-source tools that bridge risk taxonomies, benchmarks, datasets, and mitigations for operational AI governance.

2. AI Risk Taxonomy â€“ Security-Relevant Categories
ðŸ”¹ Input & Training Data Risks

Data privacy & confidentiality â€“ leakage of sensitive/confidential information in training data.
Data integrity & provenance â€“ bias, contamination, unrepresentative samples, uncertain data sources.
Improper retraining â€“ reusing undesirable outputs in training pipelines.
Usage rights â€“ restrictions from IP, licenses, or data laws.

ðŸ”¹ Inference Risks

Prompt-based attacks â€“ prompt injection, social hacking, indirect instructions, context overload.
Membership inference attacks â€“ deducing if specific data was in training.
Prompt leaking & IP disclosure â€“ extracting system prompts or proprietary information.
Sensitive data in prompts â€“ confidential/PII exposed via user input.

ðŸ”¹ Output Risks

Hallucinations â€“ factually false or misleading outputs.
Harmful/toxic content â€“ violent, discriminatory, or abusive text.
Disinformation & deepfakes â€“ spreading false narratives, impersonation.
Code generation risks â€“ insecure or harmful code outputs.
Data leakage â€“ confidential or personal data revealed in outputs.
Copyright infringement â€“ content identical/similar to protected works.

ðŸ”¹ Agentic AI Risks

Unauthorized use â€“ attackers hijacking agent behavior.
External resource exploitation â€“ attacks on tools/APIs agents rely on.
Trust boundary exploits â€“ privilege escalation in multi-agent systems.
Function call hallucinations â€“ incorrect or harmful API/tool calls.
Misaligned/redundant actions â€“ actions outside intended scope or wasted loops.
Over/under reliance â€“ misplaced human trust in agentsâ€™ decisions.

ðŸ”¹ Non-Technical Risks (Security Implications)

Lack of transparency â€“ insufficient documentation hinders accountability.
Legal accountability gaps â€“ unclear liability for AI failures.
Lack of testing diversity â€“ missing socio-technical perspectives.
Impact on human agency â€“ reduced human oversight and decision-making.

3. Tooling for AI Security

Risk Atlas Nexus
Creates a knowledge graph to align risks with taxonomies (NIST AI RMF, OWASP LLM Top 10, MIT AI Risk Repository, etc.).
Supports LLM-assisted compliance workflows and automated risk questionnaires.

Mitigation Mapping
Risks mapped to detectors (e.g., Granite Guardian for bias/prompt injection).
Risks mapped to governance frameworks (NIST RMF, EU AI Act).

GAF-Guard
Agentic framework for real-time governance.
Automates risk detection, prioritization, and monitoring of deployed LLMs.

4. Key AI Security Risks (Examples)

Evasion attacks â€“ adversarial inputs manipulating model behavior.
Membership inference â€“ exposing training dataset contents.
Prompt injection & social hacking â€“ malicious manipulation of outputs.
Data leakage â€“ confidential/PII revealed via prompts, training, or outputs.
Misuse of agents â€“ unauthorized or misaligned actions.

5. Key Takeaways

AI Risk Atlas provides a shared vocabulary for AI security and governance.
Security risks span across data, inference, outputs, and agentic autonomy.
Automation + knowledge graphs lower governance barriers but require human oversight.
Open-source Risk Atlas Nexus invites community contributions for evolving threats and mitigations.

Reference: http://media.licdn.com/dms/document/media/v2/D561FAQGDQfrpLSM-xg/feedshare-document-pdf-analyzed/B56Ziz11D3G0Ac-/0/1755363891616?e=1756339200&v=beta&t=AFgjHCl9jrg8460S0WuA3PCp0V0s0e2tT8dnq7dfgKM
