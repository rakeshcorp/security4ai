Databricks AI Security Framework

Data operations
- Raw data
- Data preparation
- Datasets
- Catalog and governance
20 specific risks:
1.1 Insufficient access controls: Access control, secure & private network access, control data access/objects and securely share it, monitor audit logs.
1.2 Missing data classification:  Classify data with tags as it’s ingested into the platform aligning with the organization’s governance requirements.
1.3 Poor data quality: Data quality checks, monitor data and AI system using single pane of glass and setup alerts.
1.4 Ineffective storage and encryption: Control access to data/objects, encryption of data at rest/in-transit.
1.5 Lack of data versioning: Version data and track change logs on large-scale datasets that are fed to your models.
1.6 Insufficient data lineage: Capture and view data lineage.
1.7 Lack of data trustworthiness: Version data and track change logs on data that are fed to your models, securely share data/AI assets.
1.8 Legality of data: Right to be forgotten, pretrain LLM to only use allowed data for inference. Track models/data lineage in model retraining.
1.9 Stale data: Use data quality checks, use near real-time data.
1.10 Lack of data access logs: Audit actions on datasets, monitor audit logs.
1.11 Compromised third-party datasets: Control access to data/objects, data quality checks, data lineage.
2.1 Preprocessing integrity: Access control, secure & private network access, control data access/objects, data quality checks, data lineage, secure model features, source control, monitor audit logs.
2.2 Feature manipulation: Access control, secure & private network access, Secure model features to prevent and track unauthorized updates to features and for lineage or traceability.
2.3 Raw data criteria: Access control, secure & private network access, Use access control lists to control access to data.
2.4 Adversarial partitions: Ensure traceability by tracking and reproducing training data partitions, linking models and runs to specific datasets, and holding human owners accountable for ML model training.
3.1 Data poisoning: Access control, secure & private network access, control data access/objects, data quality checks, data lineage, secure model features, source control, monitor audit logs.
3.2 Ineffective storage and encryption: Control access to data/objects, encryption of data at rest/in-transit.
3.3 Label flipping: Control access to data/objects, encryption of data at rest/in-transit.
4.1 Lack of traceability and transparency of model assets: Control access to data/objects, data quality checks, data lineage, Govern model assets for traceability.
4.2 Lack of end-to-end ML lifecycle: Manage end-to-end ML lifecycle for measuring, versioning, tracking model artifacts, monitoring metrics and results.



Model operations
 ML algorithm
 Evaluation
 Model build
 Model management
15 specific risks:
5.1 Lack of tracking and reproducibility of experiments
5.2 Model drift
5.3 Hyperparameters stealing
5.4 Malicious libraries
6.1 Evaluation data poisoning
6.2 Insufficient evaluation data
6.3 Lack of interpretability and explainability
7.1 Backdoor machine learning/Trojaned model
7.2 Model assets leak
7.3 ML supply chain vulnerabilities
7.4 Source code control attack
8.1 Model attribution
8.2 Model theft
8.3 Model lifecycle without HITL
8.4 Model inversion


Model deployment and serving
 Model Serving —inference requests
Model Serving — inference responses
19 specific risks:
9.1 Prompt injection
9.2 Model inversion
9.3 Model breakout
9.4 Looped input
9.5 Infer training data membership
9.6 Discover ML model ontology
9.7 Denial of service (DOS)
9.8 LLM hallucinations
9.9 Input resource control
9.10 Accidental exposure of unauthorized data to models
9.11 Model Inference API access
9.12 LLM jailbreak
9.13 Excessive agency
10.1 Lack of audit and monitoring inference quality
10.2 Output manipulation
10.3 Discover ML model ontology
10.4 Discover ML model family
10.5 Black box attacks
10.6 Sensitive data output from a model


Operations and platform
ML operations
ML platform
8 specific risks:
11.1 Lack of MLOps — repeatable enforced standards
12.1 Lack of vulnerability management
12.2 Lack of penetration testing, red teaming and bug bounty
12.3 Lack of incident response
12.4 Unauthorized privileged access
12.5 Poor SDLC
12.6 Lack of compliance
12.7 Initial access


Reeference: https://www.databricks.com/sites/default/files/2025-02/databricks-ebook-dasf-2.pdf
